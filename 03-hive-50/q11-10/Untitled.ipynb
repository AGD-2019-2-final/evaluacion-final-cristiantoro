{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext bigdata\n",
    "%hive_start\n",
    "%timeout 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 items\n",
      "drwxrwx---   - root supergroup          0 2020-02-11 03:08 /tmp/hadoop-yarn\n",
      "drwxrwxrwx   - root supergroup          0 2020-02-11 03:10 /tmp/hive\n",
      "drwxr-xr-x   - root supergroup          0 2020-02-11 04:12 /tmp/hivep10\n",
      "drwxr-xr-x   - root supergroup          0 2020-02-11 03:16 /tmp/hivep8\n",
      "drwxr-xr-x   - root supergroup          0 2020-02-11 03:54 /tmp/hivep9\n",
      "Found 6 items\n",
      "drwxrwx---   - root supergroup          0 2020-02-11 03:08 /tmp/hadoop-yarn\n",
      "drwxrwxrwx   - root supergroup          0 2020-02-11 03:10 /tmp/hive\n",
      "drwxr-xr-x   - root supergroup          0 2020-02-11 04:12 /tmp/hivep10\n",
      "drwxr-xr-x   - root supergroup          0 2020-02-11 04:13 /tmp/hivep11\n",
      "drwxr-xr-x   - root supergroup          0 2020-02-11 03:16 /tmp/hivep8\n",
      "drwxr-xr-x   - root supergroup          0 2020-02-11 03:54 /tmp/hivep9\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /tmp\n",
    "!hdfs dfs -mkdir /tmp/hivep11\n",
    "!hdfs dfs -ls /tmp/\n",
    "!hdfs dfs -copyFromLocal data.tsv /tmp/hivep11/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE IF EXISTS t0;\n",
      "OK\n",
      "Time taken: 21.487 seconds\n",
      "CREATE TABLE t0 (\n",
      "    c1 STRING,\n",
      "    c2 ARRAY<CHAR(1)>, \n",
      "    c3 MAP<STRING, INT>\n",
      "    )\n",
      "    ROW FORMAT DELIMITED \n",
      "        FIELDS TERMINATED BY '\\t'\n",
      "        COLLECTION ITEMS TERMINATED BY ','\n",
      "        MAP KEYS TERMINATED BY '#'\n",
      "        LINES TERMINATED BY '\\n';\n",
      "OK\n",
      "Time taken: 1.891 seconds\n",
      "LOAD DATA LOCAL INPATH 'data.tsv' INTO TABLE t0;\n",
      "Loading data to table default.t0\n",
      "OK\n",
      "Time taken: 3.508 seconds\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "DROP TABLE IF EXISTS t0;\n",
    "CREATE TABLE t0 (\n",
    "    c1 STRING,\n",
    "    c2 ARRAY<CHAR(1)>, \n",
    "    c3 MAP<STRING, INT>\n",
    "    )\n",
    "    ROW FORMAT DELIMITED \n",
    "        FIELDS TERMINATED BY '\\t'\n",
    "        COLLECTION ITEMS TERMINATED BY ','\n",
    "        MAP KEYS TERMINATED BY '#'\n",
    "        LINES TERMINATED BY '\\n';\n",
    "LOAD DATA LOCAL INPATH 'data.tsv' INTO TABLE t0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE IF EXISTS pt11;\n",
      "OK\n",
      "Time taken: 0.016 seconds\n",
      "CREATE TABLE pt11\n",
      "AS\n",
      "SELECT c1, size(c2), SIZE(c3)\n",
      "FROM t0;\n",
      "WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "Query ID = root_20200211042340_5c3f58f6-59af-48a5-b21b-3371e8ee0a53\n",
      "Total jobs = 3\n",
      "Launching Job 1 out of 3\n",
      "Number of reduce tasks is set to 0 since there's no reduce operator\n",
      "Starting Job = job_1581390426457_0010, Tracking URL = http://714a45eef6db:8088/proxy/application_1581390426457_0010/\n",
      "Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1581390426457_0010\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0\n",
      "2020-02-11 04:23:53,626 Stage-1 map = 0%,  reduce = 0%\n",
      "2020-02-11 04:24:05,451 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 5.42 sec\n",
      "MapReduce Total cumulative CPU time: 5 seconds 420 msec\n",
      "Ended Job = job_1581390426457_0010\n",
      "Stage-4 is selected by condition resolver.\n",
      "Stage-3 is filtered out by condition resolver.\n",
      "Stage-5 is filtered out by condition resolver.\n",
      "Moving data to directory hdfs://0.0.0.0:9000/user/hive/warehouse/.hive-staging_hive_2020-02-11_04-23-40_491_4477007973367155629-1/-ext-10002\n",
      "Moving data to directory hdfs://0.0.0.0:9000/user/hive/warehouse/pt11\n",
      "MapReduce Jobs Launched: \n",
      "Stage-Stage-1: Map: 1   Cumulative CPU: 5.42 sec   HDFS Read: 5586 HDFS Write: 309 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 5 seconds 420 msec\n",
      "OK\n",
      "Time taken: 27.454 seconds\n",
      "INSERT OVERWRITE DIRECTORY '/tmp/hivep11'\n",
      "ROW FORMAT DELIMITED FIELDS TERMINATED BY ','\n",
      "COLLECTION ITEMS TERMINATED BY ':'\n",
      "SELECT * FROM pt11;\n",
      "WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "Query ID = root_20200211042408_35fc3a47-ba41-454f-bc78-17d959329a87\n",
      "Total jobs = 3\n",
      "Launching Job 1 out of 3\n",
      "Number of reduce tasks is set to 0 since there's no reduce operator\n",
      "Starting Job = job_1581390426457_0011, Tracking URL = http://714a45eef6db:8088/proxy/application_1581390426457_0011/\n",
      "Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1581390426457_0011\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0\n",
      "2020-02-11 04:24:23,443 Stage-1 map = 0%,  reduce = 0%\n",
      "2020-02-11 04:24:33,895 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.98 sec\n",
      "MapReduce Total cumulative CPU time: 2 seconds 980 msec\n",
      "Ended Job = job_1581390426457_0011\n",
      "Stage-3 is selected by condition resolver.\n",
      "Stage-2 is filtered out by condition resolver.\n",
      "Stage-4 is filtered out by condition resolver.\n",
      "Moving data to directory hdfs://0.0.0.0:9000/tmp/hivep11/.hive-staging_hive_2020-02-11_04-24-08_199_3957883711508218508-1/-ext-10000\n",
      "Moving data to directory /tmp/hivep11\n",
      "MapReduce Jobs Launched: \n",
      "Stage-Stage-1: Map: 1   Cumulative CPU: 2.98 sec   HDFS Read: 3673 HDFS Write: 240 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 2 seconds 980 msec\n",
      "OK\n",
      "Time taken: 27.011 seconds\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "DROP TABLE IF EXISTS pt11;\n",
    "CREATE TABLE pt11\n",
    "AS\n",
    "SELECT c1, size(c2), SIZE(c3)\n",
    "FROM t0;\n",
    "\n",
    "INSERT OVERWRITE DIRECTORY '/tmp/hivep11'\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY ','\n",
    "COLLECTION ITEMS TERMINATED BY ':'\n",
    "SELECT * FROM pt11;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E,3,5\n",
      "A,3,4\n",
      "B,4,4\n",
      "A,2,4\n",
      "C,4,4\n",
      "A,2,5\n",
      "A,3,6\n",
      "B,2,3\n",
      "E,4,6\n",
      "B,4,6\n",
      "C,4,5\n",
      "C,4,3\n",
      "D,4,5\n",
      "E,2,3\n",
      "B,2,5\n",
      "D,2,4\n",
      "E,3,6\n",
      "D,2,3\n",
      "E,4,3\n",
      "E,2,3\n",
      "E,2,3\n",
      "E,3,3\n",
      "D,3,3\n",
      "A,3,5\n",
      "E,2,6\n",
      "E,3,6\n",
      "A,3,3\n",
      "E,3,5\n",
      "A,2,5\n",
      "C,4,6\n",
      "A,2,5\n",
      "D,2,6\n",
      "E,2,4\n",
      "B,3,6\n",
      "B,3,5\n",
      "D,2,3\n",
      "B,2,5\n",
      "C,4,3\n",
      "E,2,3\n",
      "E,3,3\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /tmp/hivep11/000000_0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -copyToLocal /tmp/hivep11/000000_0 output;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE pto11;\n",
      "OK\n",
      "Time taken: 0.467 seconds\n",
      "DROP TABLE t0;\n",
      "OK\n",
      "Time taken: 0.846 seconds\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "DROP TABLE pto11;\n",
    "DROP TABLE t0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'derby.log': Text file busy\n"
     ]
    }
   ],
   "source": [
    "!rm *.tsv *.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%hive_quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
